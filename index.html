<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Vocal Confidence Builder</title>
<link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet" />
<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet" />
<style>
/* Custom Styles for Modern UI & Mobile-First */
:root {
  --primary-color: #4f46e5;
  --primary-dark: #4338ca;
  --secondary-bg: #f3f4f6;
  --text-color-primary: #1f2937;
  --text-color-secondary: #6b7280;
  --border-color: #e5e7eb;
  --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
}
html, body {
  height: 100%;
  font-family: 'Inter', sans-serif;
}
body {
  background-color: var(--secondary-bg);
}
.app-container {
  display: flex;
  flex-direction: column;
  height: 100%;
  padding: 1rem;
}
.chat-window {
  flex-grow: 1;
  overflow-y: auto;
  scroll-behavior: smooth;
  padding: 1rem;
  background-color: white;
  border-radius: 1rem;
  border: 1px solid var(--border-color);
  box-shadow: var(--shadow-lg);
  display: flex;
  flex-direction: column;
}
.message {
  max-width: 85%;
  padding: 0.75rem 1rem;
  border-radius: 1.25rem;
  margin-bottom: 0.75rem;
  line-height: 1.5;
  word-wrap: break-word;
}
.user-message {
  background-color: var(--primary-color);
  color: white;
  align-self: flex-end;
  border-bottom-right-radius: 0.25rem;
}
.ai-message {
  background-color: var(--secondary-bg);
  color: var(--text-color-primary);
  align-self: flex-start;
  border-bottom-left-radius: 0.25rem;
}
.input-area {
  position: sticky;
  bottom: 0;
  left: 0;
  right: 0;
  z-index: 1000;
  padding-top: 1rem;
  background-color: var(--secondary-bg);
}
.pulse-animate {
  animation: pulse-ring 1s cubic-bezier(0, 0.9, 0.3, 1) infinite;
}
@keyframes pulse-ring {
  0% {
    transform: scale(0.33);
    opacity: 1;
  }
  100% {
    transform: scale(1);
    opacity: 0;
  }
}
</style>
</head>
<body class="bg-gray-100 antialiased">
<div class="app-container max-w-lg mx-auto md:p-8">
  <header class="text-center py-4 md:py-8">
    <div class="flex items-center justify-center">
      <span class="text-3xl md:text-5xl mr-3">ðŸŒŸ</span>
      <h1 class="text-3xl font-bold text-gray-800">Vocal Confidence</h1>
    </div>
    <p class="mt-2 text-lg text-gray-600">
      Build confidence with simple, complete sentences.
    </p>
  </header>
  <div class="chat-window">
    <div id="chat-history" class="flex flex-col">
      </div>
  </div>
  <div class="input-area">
    <div id="interim-results" class="text-sm italic text-center text-gray-500 h-6 mb-2"></div>
    <div class="relative flex items-center justify-center">
      <button
        id="action-button"
        class="relative w-full py-4 text-white font-semibold rounded-full shadow-lg transition-all duration-300 ease-in-out transform hover:scale-105"
        style="background-color: var(--primary-color);"
      >
        <span class="absolute w-full h-full rounded-full" style="background-color: var(--primary-color);"></span>
        <span class="relative z-10">Start Lesson</span>
      </button>
      <input
        type="text"
        id="fallback-text-input"
        class="hidden w-full px-5 py-3 border border-gray-300 rounded-full focus:outline-none focus:ring-2"
        style="focus-ring-color: var(--primary-color);"
        placeholder="Type your response here..."
      />
    </div>
  </div>
</div>
<script>
  const State = {
    IDLE: 'idle',
    LISTENING: 'listening',
    PROCESSING: 'processing',
    PLAYING_AUDIO: 'playing_audio',
  };
  const SPEAK_VOICE = "Zephyr";
  const API_KEY = ""; // Insert your API key here
  const API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent";

  const elements = {
    chatHistory: document.getElementById('chat-history'),
    actionButton: document.getElementById('action-button'),
    interimResultsEl: document.getElementById('interim-results'),
    fallbackInput: document.getElementById('fallback-text-input'),
  };

  let currentState = State.IDLE;
  let audioContext;
  let recognition;
  let conversationHistory = [];
  let lessonStage = 0;

  const lessonSteps = [
    { type: 'ai-message', content: "Hi there! Click 'Start Lesson' below to begin." },
    { type: 'user-input', content: "Hello! Let's begin our lesson. Take a moment to relax. Inhale slowly for 4 seconds, and exhale for 6 seconds. When you are ready, please tell me your name." },
    { type: 'user-input', content: "That's great! Now, what is your favorite hobby or something you like to do?" },
    { type: 'user-input', content: "That's wonderful! We're almost done. What's one thing you feel more confident about now?" },
    { type: 'end-message', content: "Thatâ€™s fantastic to hear! Our lesson is complete. You did a great job today!" },
  ];

  // Utility functions
  const setState = (newState) => {
    currentState = newState;
    updateUI();
  };

  const updateUI = () => {
    const { actionButton, fallbackInput } = elements;
    switch (currentState) {
      case State.IDLE:
        actionButton.textContent = lessonSteps[lessonStage]?.buttonText || "Start Lesson";
        actionButton.style.display = 'block';
        fallbackInput.style.display = 'none';
        actionButton.disabled = false;
        break;
      case State.LISTENING:
        actionButton.textContent = "Listening...";
        actionButton.disabled = true;
        actionButton.querySelector('span:first-child')?.classList.add('pulse-animate');
        break;
      case State.PROCESSING:
        actionButton.textContent = "Processing...";
        actionButton.disabled = true;
        break;
      case State.PLAYING_AUDIO:
        actionButton.textContent = "Playing...";
        actionButton.disabled = true;
        break;
    }
    // Remove pulse on any state change that's not listening
    if (currentState !== State.LISTENING) {
      actionButton.querySelector('span:first-child')?.classList.remove('pulse-animate');
    }
  };

  const base64ToArrayBuffer = (base64) => {
    const binaryString = window.atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  };

  const playAudio = async (arrayBuffer) => {
    if (!audioContext) audioContext = new (window.AudioContext || window.webkitAudioContext)();
    try {
      const buffer = await audioContext.decodeAudioData(arrayBuffer);
      const source = audioContext.createBufferSource();
      source.buffer = buffer;
      source.connect(audioContext.destination);
      source.start(0);
      return new Promise((res) => { source.onended = res; });
    } catch (err) {
      console.error("Audio playback error:", err);
      addMessage('ai', "Sorry, I'm having trouble with my voice right now.");
      throw err;
    }
  };

  const addMessage = (role, text) => {
    const messageDiv = document.createElement('div');
    messageDiv.className = `message ${role === 'user' ? 'user-message' : 'ai-message'} shadow`;
    messageDiv.textContent = text;
    elements.chatHistory.appendChild(messageDiv);
    elements.chatHistory.scrollTop = elements.chatHistory.scrollHeight;
    conversationHistory.push({ role: role === 'user' ? 'user' : 'model', parts: [{ text }] });
  };

  const handleApiRequest = async (payload) => {
    try {
      const response = await fetch(`${API_URL}?key=${API_KEY}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload),
      });
      if (!response.ok) {
        const errText = await response.text();
        throw new Error(`API Error: ${response.status} - ${errText}`);
      }
      return await response.json();
    } catch (err) {
      console.error("API call error:", err);
      addMessage('ai', "I'm sorry, I couldn't get a response. Let's try again.");
      setState(State.IDLE);
      return null;
    }
  };

  // Main logic
  const processLessonStage = async () => {
    const step = lessonSteps[lessonStage];
    if (!step) return;
    if (step.type === 'end-message') {
      await speak(step.content);
      setState(State.IDLE);
      elements.actionButton.textContent = "Lesson Complete";
      elements.actionButton.disabled = true;
      return;
    }
    if (step.type === 'ai-message' || step.type === 'user-input') {
      addMessage('ai', step.content);
      await speak(step.content);
      // Wait for user input if required
      if (step.type === 'user-input') {
        setState(State.IDLE);
        elements.actionButton.textContent = "Click to Speak";
      } else {
        lessonStage++;
        processLessonStage();
      }
    }
  };

  const speak = async (text) => {
    setState(State.PROCESSING);
    const payload = {
      contents: [{ parts: [{ text }] }],
      generationConfig: {
        responseModalities: ["AUDIO"],
        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: SPEAK_VOICE } } },
      },
    };
    const data = await handleApiRequest(payload);
    if (data && data.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data) {
      const audioData = data.candidates[0].content.parts[0].inlineData.data;
      setState(State.PLAYING_AUDIO);
      await playAudio(base64ToArrayBuffer(audioData));
    }
  };

  const handleUserResponse = async (text) => {
    addMessage('user', text);
    setState(State.PROCESSING);
    // Use the last 5 messages for context to save tokens and improve performance
    const recentHistory = conversationHistory.slice(-5);
    const systemInstruction = "You are an English language tutor. Keep responses short and encouraging, acting as a conversational partner. Do not act as a lesson guide. Just respond naturally to the user's last message.";
    const payload = {
      systemInstruction: { parts: [{ text: systemInstruction }] },
      contents: recentHistory,
      generationConfig: {
        responseModalities: ["AUDIO", "TEXT"],
        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: SPEAK_VOICE } } },
      },
    };
    const data = await handleApiRequest(payload);
    if (data) {
      const aiText = data.candidates?.[0]?.content?.parts?.[0]?.text;
      const audioData = data.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
      if (aiText) addMessage('ai', aiText);
      if (audioData) await playAudio(base64ToArrayBuffer(audioData));
    }
    lessonStage++;
    processLessonStage();
  };

  // Event Listeners and Initialization
  document.addEventListener('DOMContentLoaded', () => {
    if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
      const SpeechRec = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRec();
      recognition.lang = 'en-US';
      recognition.interimResults = true;
      recognition.maxAlternatives = 1;

      recognition.onstart = () => setState(State.LISTENING);
      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        elements.interimResultsEl.textContent = transcript;
        if (event.results[0].isFinal) {
          handleUserResponse(transcript);
        }
      };
      recognition.onend = () => {
        elements.interimResultsEl.textContent = '';
        if (currentState === State.LISTENING) setState(State.IDLE);
      };
      recognition.onerror = (e) => {
        console.error("Recognition error:", e);
        addMessage('ai', "Sorry, I didn't catch that. Please try again.");
        setState(State.IDLE);
      };

      elements.actionButton.addEventListener('click', () => {
        if (currentState === State.IDLE && recognition) {
          recognition.start();
        } else {
          lessonStage++;
          processLessonStage();
        }
      });
    } else {
      // Fallback to text input
      elements.actionButton.style.display = 'none';
      elements.fallbackInput.style.display = 'block';
      elements.fallbackInput.addEventListener('keyup', (e) => {
        if (e.key === 'Enter' && e.target.value.trim()) {
          handleUserResponse(e.target.value.trim());
          e.target.value = '';
        }
      });
    }
    // Start the lesson
    processLessonStage();
    updateUI();
  });
</script>
</body>
</html>
